{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MoCnFosGkGL3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import keras\n",
    "## Run on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvXHb6dhCYZ0",
    "outputId": "53631760-6b9a-4a24-f1fc-b120aa975e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 13 06:48:00 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   54C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_XOJzFElu0e"
   },
   "outputs": [],
   "source": [
    "### NOTE: Please connect to GPU runtime on this Google Colab Notebook\n",
    "os.environ['KAGGLE_USERNAME'] = \" (your kaggle username )\" # username from the json file\n",
    "os.environ['KAGGLE_KEY'] = \" (your kaggle key )\" # key from the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNs2Zk16zHbt"
   },
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "### TO RESET THE GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GH_Z6nskLsz"
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIgHDv4xmwYG",
    "outputId": "a3047e9b-9d16-4636-e73e-051f3c282525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading marco-protein-crystal-image-recognition.zip to /content\n",
      "100% 2.05G/2.05G [00:28<00:00, 16.8MB/s]\n",
      "100% 2.05G/2.05G [00:28<00:00, 76.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d grantwiersum/marco-protein-crystal-image-recognition\n",
    "### DOWNLOADING THE DATASET FROM THE KAGGLE WEBISTE,\n",
    "## you may access many more gb of data from https://marco.ccr.buffalo.edu/data/test/ and https://marco.ccr.buffalo.edu/data/train/\n",
    "## already in tfrecord format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdNZS_He0mZd"
   },
   "outputs": [],
   "source": [
    "!unzip -q /content/marco-protein-crystal-image-recognition.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILuUcFQAkGL5"
   },
   "outputs": [],
   "source": [
    "\n",
    "### FUNCTION TO EXTRACT FEATURES FROM THE TFRECORDS FILE FORMAT\n",
    "\n",
    "def _extract_fn(ds):\n",
    "        # Extract features using the keys set during creation\n",
    "        features = {\n",
    "        \"image/class/label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "         \"image/encoded\":  tf.io.FixedLenFeature([],tf.string)\n",
    "        }\n",
    "        \n",
    "        # Extract the data record\n",
    "        sample = tf.io.parse_single_example(ds, features)\n",
    "        image = tf.image.decode_jpeg(sample['image/encoded'],channels=3) \n",
    "        reshaped = tf.image.resize(image,[499,499],preserve_aspect_ratio=False)\n",
    "        label = sample['image/class/label']\n",
    "        if(label==0):\n",
    "          lb=[1,0,0,0]\n",
    "        elif(label==1):\n",
    "          lb=[0,1,0,0] \n",
    "        elif(label==2):\n",
    "          lb=[0,0,1,0]\n",
    "        else:\n",
    "          lb=[0,0,0,1]    \n",
    "    \n",
    "        return reshaped,lb     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bs_zHse4AuXg"
   },
   "outputs": [],
   "source": [
    "\n",
    "def flip_left_right(ds):\n",
    "        features = {\n",
    "          \"image/class/label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "          \"image/encoded\":  tf.io.FixedLenFeature([],tf.string)\n",
    "          }\n",
    "        seed = (2,3)\n",
    "        # Extract the data record\n",
    "        sample = tf.io.parse_single_example(ds, features)\n",
    "        image = tf.image.decode_jpeg(sample['image/encoded'],channels=3) \n",
    "        reshaped = tf.image.resize(image,[499,499],preserve_aspect_ratio=False)\n",
    "        label = sample['image/class/label']\n",
    "        if(label==0):\n",
    "          lb=[1,0,0,0]\n",
    "        elif(label==1):\n",
    "          lb=[0,1,0,0] \n",
    "        elif(label==2):\n",
    "          lb=[0,0,1,0]\n",
    "        else:\n",
    "          lb=[0,0,0,1]\n",
    "        reshaped = tf.image.stateless_random_flip_left_right(reshaped, seed);\n",
    "        return  reshaped,lb   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6F1vwuPDQnf"
   },
   "outputs": [],
   "source": [
    "def flip_up_down(ds):\n",
    "        features = {\n",
    "          \"image/class/label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "          \"image/encoded\":  tf.io.FixedLenFeature([],tf.string)\n",
    "          }\n",
    "          \n",
    "        # Extract the data record\n",
    "        sample = tf.io.parse_single_example(ds, features)\n",
    "        image = tf.image.decode_jpeg(sample['image/encoded'],channels=3) \n",
    "        reshaped = tf.image.resize(image,[499,499],preserve_aspect_ratio=False)\n",
    "        seed=(2,3)\n",
    "        label = sample['image/class/label']\n",
    "        \n",
    "        if(label==0):\n",
    "          lb=[1,0,0,0]\n",
    "        elif(label==1):\n",
    "          lb=[0,1,0,0] \n",
    "        elif(label==2):\n",
    "          lb=[0,0,1,0]\n",
    "        else:\n",
    "          lb=[0,0,0,1]    \n",
    "       \n",
    "        reshaped = tf.image.stateless_random_flip_left_right(reshaped, seed);\n",
    "         \n",
    "        return reshaped, lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvze9YzVhssM"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "### FUNCTION TO CREATE DATASET\n",
    "def create_dataset(file_list,shuffle_buffer_size=1000):\n",
    "    ds = tf.data.TFRecordDataset(file_list)\n",
    "    ds = ds.shuffle(buffer_size=len(file_list))\n",
    "    ds1 = ds.map(flip_up_down,num_parallel_calls=AUTOTUNE)\n",
    "    ds2 = ds.map(flip_left_right,num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.map(_extract_fn,num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.concatenate(ds1)\n",
    "    ds = ds.concatenate(ds2)\n",
    "    ds= ds.batch(BATCH_SIZE)  ### SPLITTING THE DATA INTO BATCHES\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE) ### PREFETCH WILL FEED THE EXAMPLES TO MODEL ONE EXAMPLE AT A TIME, MORE MEMORY EFFICIENT AND CONVENIENT\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArUnT9f7kGL7"
   },
   "outputs": [],
   "source": [
    "filepaths = ['/content/train-00001-of-00407','/content/train-00002-of-00407','/content/train-00003-of-00407','/content/train-00004-of-00407','/content/train-00005-of-00407','/content/train-00006-of-00407','/content/train-00007-of-00407','/content/train-00008-of-00407','/content/train-00009-of-00407','/content/train-00010-of-00407','/content/train-00011-of-00407','/content/train-00012-of-00407','/content/drive/MyDrive/Study Project 2019A7PS0097U(Giri)/train-00027-of-00407','/content/drive/MyDrive/Study Project 2019A7PS0097U(Giri)/train-00028-of-00407','/content/drive/MyDrive/Study Project 2019A7PS0097U(Giri)/train-00029-of-00407','/content/drive/MyDrive/Study Project 2019A7PS0097U(Giri)/train-00030-of-00407','/content/drive/MyDrive/Study Project 2019A7PS0097U(Giri)/train-00031-of-00407','/content/drive/MyDrive/Study Project 2019A7PS0097U(Giri)/train-00032-of-00407','/content/drive/MyDrive/Study Project 2019A7PS0097U(Giri)/train-00033-of-00407','/content/drive/MyDrive/Study Project 2019A7PS0097U(Giri)/train-00013-of-00407']\n",
    "train_ds = create_dataset(filepaths)  ### TRAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RF6Jby926Rj-"
   },
   "outputs": [],
   "source": [
    "# del train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DzdXXIVE4O78"
   },
   "outputs": [],
   "source": [
    "count1=0\n",
    "count2=0\n",
    "count3=0\n",
    "count4=0\n",
    "seed = (2,3)\n",
    "index =0;\n",
    "ds1 = tf.TensorArray(dtype=tf.float32,size=0,dynamic_size=True)\n",
    "for sample in train_ds:\n",
    "    label = sample[1]\n",
    "    if(label[0]):\n",
    "      count1+=1;\n",
    "    elif(label[1]):\n",
    "      count2+=1;\n",
    "    elif(label[2]):\n",
    "      count3+=1;\n",
    "    elif(label[3]):\n",
    "      count4+=1;      \n",
    "print(\"Number of examples for \\n\");\n",
    "print(\"Class 1:\"+str(count1)+\"Class 2:\"+str(count2)+\"Class 3:\"+str(count3)+\"Class 4:\"+str(count4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vrrw4xJkGL7"
   },
   "outputs": [],
   "source": [
    "test_filepaths = ['test-00001-of-00046','test-00002-of-00046','test-00003-of-00046','/content/drive/MyDrive/Study Project 2019A7PS0097U(Giri)/test-00010-of-00046','/content/drive/MyDrive/Study Project 2019A7PS0097U(Giri)/test-00012-of-00046','/content/drive/MyDrive/Study Project 2019A7PS0097U(Giri)/test-00013-of-00046']\n",
    "test_ds = create_dataset(test_filepaths)## TEST DATASET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XR2E8_irkGMA"
   },
   "outputs": [],
   "source": [
    "#def show_any_image(index):\n",
    "#    msg =\"Type is:\"\n",
    "#    if y_train[index]==0:\n",
    "#        msg+=\"Clear\"\n",
    "#    elif y_train[index]==1:\n",
    "#        msg+=\"Crystal\"\n",
    "#    elif y_train[index]==2:\n",
    "#        msg+=\"Precipitate\"\n",
    "#    else:\n",
    "#        msg+=\"Others\"\n",
    "#    \n",
    "#    plt.imshow(x_train[index])\n",
    "#    plt.title(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kq4BWzfvxmJC"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a callback that saves the model's weights so that it can be accessed later, because the model is not permanent on google colab notebooks\n",
    "# saving the model frequently so that progress is not lost\n",
    "checkpoint_path = \"/content/drive/MyDrive/Project/checkpoints/\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouc7oqfz-kyk"
   },
   "outputs": [],
   "source": [
    "### To track the model training accuracy live graph (accuracy, loss , etc)\n",
    "import datetime\n",
    "log_dir = \"/content/drive/MyDrive/Project/logs/\"\n",
    "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,write_graph=True,\n",
    "                         write_images=True,\n",
    "                         update_freq='epoch',\n",
    "                         profile_batch=2,\n",
    "                         embeddings_freq=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxTuMzis-60n"
   },
   "source": [
    "# Training on the InceptionV3 model\n",
    "### from the imagenet competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRCQ9GKwkGMA",
    "outputId": "18a261cb-fce4-49df-99dc-6b0e3c31cac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "## didnt get as good accuracy\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3  \n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D,Input\n",
    "input_tensor = Input(shape=(499, 499, 3))\n",
    "# create the base pre-trained model\"\n",
    "base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False,input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TL5-0Zi0kGMB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import AveragePooling2D,Flatten,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "headModel = base_model.output\n",
    "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dense(4, activation=\"softmax\")(headModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9T_SH4XkGMB"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwy-jUuCkGMC"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lw3DZxeSkGMC"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "\tlayer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkztQvTImHSO"
   },
   "outputs": [],
   "source": [
    "del train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNJBlm5RkGMC"
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=3e-2)\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt,metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lS5_uI6JFDzP"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/Project/logs/train/\"\n",
    "%tensorboard --logdir \"/content/drive/MyDrive/Project/logs/exp2/\"\n",
    "### TO VIEW GRAPHS FOR WHILE TRAINING THE DATA (ACCURACY , LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "zxvLIXRhkGME",
    "outputId": "94debf10-ec5e-403e-a7c1-b174e95ccdd0"
   },
   "outputs": [],
   "source": [
    "model.fit(train_ds,verbose=1,epochs=5,callbacks=[tensorboard_callback,cp_callback],validation_data=test_ds)\n",
    "model.save('/content/drive/MyDrive/Models/InceptionV3/') ## got maximum of 74% accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OuOX2fZ_2m_"
   },
   "source": [
    "# Training on Xception model\n",
    " this model got better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSxqoRaIkGME",
    "outputId": "fa16fa96-9f48-4348-c233-0fcbd3e56023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "## performed relatively better\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D,Input\n",
    "\n",
    "input_tensor2 = Input(shape=(499, 499, 3))\n",
    "input_tensor2 = tf.keras.applications.xception.preprocess_input(input_tensor2)\n",
    "base_model2 = tf.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=input_tensor2,\n",
    "    input_shape=(499,499,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgSkHFzdQ2dB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import AveragePooling2D,Flatten,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "headModel2 = base_model2.output\n",
    "headModel2 = AveragePooling2D(pool_size=(4, 4))(headModel2)\n",
    "headModel2 = Flatten(name=\"flatten\")(headModel2)\n",
    "headModel2 = Dense(128, activation=\"relu\")(headModel2)\n",
    "headModel2 = Dense(128, activation=\"relu\")(headModel2)\n",
    "headModel2 = Dense(4, activation=\"softmax\")(headModel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prNYoLDERCPh"
   },
   "outputs": [],
   "source": [
    "model2 = Model(inputs=base_model2.input, outputs=headModel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLq2lwW6RHC_"
   },
   "outputs": [],
   "source": [
    "for layer in base_model2.layers:\n",
    "\tlayer.trainable = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pdcItG3RH1P"
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=2e-2)\n",
    "model2.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt,metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UicJC4TG2PkJ"
   },
   "outputs": [],
   "source": [
    "## TO LOAD THE MODEL\n",
    "model2= tf.keras.models.load_model('/content/drive/MyDrive/Project/Xception/')\n",
    "### DOWNLOAD LINK FOR THE TRAINED MODEL: https://drive.google.com/drive/folders/194ySuLOc4qloytkw0uMhHYebadmKjZnx?usp=sharing\n",
    "## use this as base for further training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "_0hg4th3RM9Y",
    "outputId": "4d87fc9e-6d52-49ef-f1a6-9151e80e0f1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "      1/Unknown - 8s 8s/step - loss: 0.3883 - categorical_accuracy: 0.8750"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b65d8b9b8b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#MODEL TRAINING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcp_callback\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#Maximum accuracy: 79%(without data augmentation).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[2048,1536,1,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/block14_sepconv2/separable_conv2d (defined at <ipython-input-27-b65d8b9b8b86>:2) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_37968]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "#MODEL TRAINING\n",
    "model2.fit(train_ds,verbose=1,epochs=2,callbacks=[tensorboard_callback,cp_callback ],validation_data=test_ds) \n",
    "#Maximum accuracy: 83%\n",
    "## t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Re3p3mkf1tvX",
    "outputId": "4721685c-fff7-4f19-dc16-a0a0e8857a4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Study Project resources/Xception/assets\n"
     ]
    }
   ],
   "source": [
    "##TO SAVE THE MODEL\n",
    "model2.save('/content/drive/MyDrive/Project/Xception/')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVZC64uJXZpu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8om2NOYPUNrJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
